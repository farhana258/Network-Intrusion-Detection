{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:11:17.120846Z","iopub.status.busy":"2021-06-14T09:11:17.120564Z","iopub.status.idle":"2021-06-14T09:11:17.126192Z","shell.execute_reply":"2021-06-14T09:11:17.125078Z","shell.execute_reply.started":"2021-06-14T09:11:17.120821Z"},"trusted":true},"outputs":[],"source":["# Import packages\n","import os \n","import warnings\n","import gc\n","\n","import pandas as pd \n","import numpy as np \n","from plotly.subplots import make_subplots\n","import plotly.express as px \n","import plotly.graph_objects as go\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import precision_recall_fscore_support, classification_report\n","\n","# Configuration\n","warnings.simplefilter('ignore')\n","pd.set_option('max_columns', 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:13:39.878811Z","iopub.status.busy":"2021-06-14T09:13:39.878499Z","iopub.status.idle":"2021-06-14T09:13:39.881929Z","shell.execute_reply":"2021-06-14T09:13:39.880977Z","shell.execute_reply.started":"2021-06-14T09:13:39.878785Z"},"trusted":true},"outputs":[],"source":["# Variable definitions\n","DATA_PATH = \"../input/network-intrusion-detection\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:13:40.145171Z","iopub.status.busy":"2021-06-14T09:13:40.144824Z","iopub.status.idle":"2021-06-14T09:13:40.152724Z","shell.execute_reply":"2021-06-14T09:13:40.151833Z","shell.execute_reply.started":"2021-06-14T09:13:40.145138Z"},"trusted":true},"outputs":[],"source":["# Utility functions \n","def describe(df, stats):\n","    '''Describe the basic information of the raw dataframe.\n","    \n","    Parameters:\n","        df: pd.DataFrame, raw dataframe to be analyzed\n","        stats: boolean, whether to get descriptive statistics \n","    \n","    Return:\n","        None\n","    '''\n","    df_ = df.copy(deep=True)   # Copy of the raw dataframe\n","    n_features = df_.shape[1]\n","    if n_features > pd.get_option(\"max_columns\"):\n","        # If the feature (column) number is greater than max number of columns displayed\n","        warnings.warn(\"Please reset the display-related options max_columns \\\n","                      to enable the complete display.\", \n","                      UserWarning) \n","    print(\"=====Basic information=====\")\n","    display(df_.info())\n","    get_nan_ratios(df_)\n","    if stats:\n","        print(\"=====Description=====\")\n","        numeric_col_num = df_.select_dtypes(include=np.number).shape[1]   # Number of cols in numeric type\n","        if numeric_col_num != 0:\n","            display(df_.describe())\n","        else:\n","            print(\"There's no description of numeric data to display!\")\n","    del df_\n","    gc.collect()\n","\n","def get_nan_ratios(df):\n","    '''Get NaN ratios of columns with NaN values.\n","    \n","    Parameters:\n","        df: pd.DataFrame, raw dataframe to be analyzed\n","        \n","    Return:\n","        None\n","    '''\n","    df_ = df.copy()   # Copy of the raw dataframe\n","    nan_ratios = df_.isnull().sum() / df_.shape[0] * 100   # Ratios of value nan in each column\n","    nan_ratios = pd.DataFrame([df_.columns, nan_ratios]).T   # Take transpose \n","    nan_ratios.columns = [\"Columns\", \"NaN ratios\"]\n","    nan_ratios = nan_ratios[nan_ratios[\"NaN ratios\"] != 0.0]\n","    print(\"=====NaN ratios of columns with NaN values=====\")\n","    if len(nan_ratios) == 0:\n","        print(\"There isn't any NaN value in the dataset!\")\n","    else:\n","        display(nan_ratios)\n","    del df_\n","    gc.collect() "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:13:40.662927Z","iopub.status.busy":"2021-06-14T09:13:40.662605Z","iopub.status.idle":"2021-06-14T09:13:40.824014Z","shell.execute_reply":"2021-06-14T09:13:40.823078Z","shell.execute_reply.started":"2021-06-14T09:13:40.662898Z"},"trusted":true},"outputs":[],"source":["# Split the training set and testing set (hold-out).\n","df = pd.read_csv(os.path.join(DATA_PATH, \"Train_data.csv\"))\n","X, y = df.iloc[:, :-1], df['class']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n","X_train.reset_index(drop=True, inplace=True)\n","X_test.reset_index(drop=True, inplace=True)\n","y_train.reset_index(drop=True, inplace=True)\n","X_test.reset_index(drop=True, inplace=True)\n","print(f\"Shape of X_train: {X_train.shape}\\nShape of X_test: {X_test.shape}\")\n","print(f\"Shape of y_train: {y_train.shape}\\nShape of y_test: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:14:03.632317Z","iopub.status.busy":"2021-06-14T09:14:03.631973Z","iopub.status.idle":"2021-06-14T09:14:04.042009Z","shell.execute_reply":"2021-06-14T09:14:04.041075Z","shell.execute_reply.started":"2021-06-14T09:14:03.632288Z"},"trusted":true},"outputs":[],"source":["print(\"=====DataFrame: X_train=====\")\n","display(X_train.head())\n","describe(X_train, stats=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:14:17.898603Z","iopub.status.busy":"2021-06-14T09:14:17.898272Z","iopub.status.idle":"2021-06-14T09:14:17.909294Z","shell.execute_reply":"2021-06-14T09:14:17.908181Z","shell.execute_reply.started":"2021-06-14T09:14:17.898576Z"},"trusted":true},"outputs":[],"source":["cat_features = ['protocol_type', 'service', 'flag']\n","for f in cat_features:\n","    print(f\"=====Unique values of {f}=====\")\n","    unique_vals = X_train[f].unique()\n","    print(unique_vals)\n","    print(f\"Number of unique values: {len(unique_vals)}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:14:30.865925Z","iopub.status.busy":"2021-06-14T09:14:30.865643Z","iopub.status.idle":"2021-06-14T09:14:31.005482Z","shell.execute_reply":"2021-06-14T09:14:31.004674Z","shell.execute_reply.started":"2021-06-14T09:14:30.865901Z"},"trusted":true},"outputs":[],"source":["for f in cat_features:\n","    val_counts = X_train[f].value_counts()\n","    fig = go.Figure()\n","    fig.add_trace(go.Pie(\n","        labels=val_counts.index,\n","        values=val_counts\n","    ))\n","    fig.update_traces(textposition='inside') \n","    fig.update_layout(\n","        title=f\"Pie Chart of {f}\",\n","        uniformtext_minsize=12, \n","        uniformtext_mode='hide'\n","    )\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:14:45.553294Z","iopub.status.busy":"2021-06-14T09:14:45.552943Z","iopub.status.idle":"2021-06-14T09:14:46.313836Z","shell.execute_reply":"2021-06-14T09:14:46.311702Z","shell.execute_reply.started":"2021-06-14T09:14:45.553261Z"},"trusted":true},"outputs":[],"source":["numeric_features = [col for col in X_train.columns if col not in cat_features]\n","\n","fig = make_subplots(rows=10, cols=4, subplot_titles=numeric_features)\n","for i in range(1, 11):\n","    for j in range(1, 5):\n","        feature_idx = 4 * (i-1) + (j-1)\n","        if feature_idx == len(numeric_features):\n","            break\n","        feature = numeric_features[feature_idx]\n","        feature_series = X_train[feature]\n","        sub_fig = go.Histogram(x=feature_series, name=feature)\n","        fig.add_trace(\n","            sub_fig,\n","            row=i,\n","            col=j\n","        )\n","        \n","fig.update_layout(height=1200, title_text=\"Univariate Distribution of Numeric Features\") \n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:15:18.376694Z","iopub.status.busy":"2021-06-14T09:15:18.376391Z","iopub.status.idle":"2021-06-14T09:15:18.456647Z","shell.execute_reply":"2021-06-14T09:15:18.455794Z","shell.execute_reply.started":"2021-06-14T09:15:18.376667Z"},"trusted":true},"outputs":[],"source":["n_samples = X_train.shape[0]   # Total number of samples\n","\n","# Get the proportion of the value with the most count in each feature\n","max_proportions = pd.DataFrame()\n","for f in numeric_features:\n","    feature_series = X_train[f]\n","    max_proportion = np.max(feature_series.value_counts()) / n_samples\n","    max_proportions[f] = [max_proportion]\n","max_proportions.index = [\"Max Proportion\"]\n","\n","# Get the variance of each feature \n","vars = pd.DataFrame(X_train.var()).T\n","vars.index = [\"Variance\"]\n","\n","disp_and_var = max_proportions.append(vars)\n","print(\"=====Statistical dispersion and variation=====\")\n","display(disp_and_var)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:15:35.101522Z","iopub.status.busy":"2021-06-14T09:15:35.101216Z","iopub.status.idle":"2021-06-14T09:15:35.958488Z","shell.execute_reply":"2021-06-14T09:15:35.957402Z","shell.execute_reply.started":"2021-06-14T09:15:35.101497Z"},"trusted":true},"outputs":[],"source":["# Filter out features with high \"max proportion\" or low \"variance\"\n","disp_and_var_T = disp_and_var.T   # Take the transpose\n","features_remained = disp_and_var_T[(disp_and_var_T['Max Proportion'] < 0.99) & disp_and_var_T['Variance'] > 0.001].index.tolist()\n","X_train = X_train.loc[:, features_remained]\n","print(f\"After filtering, there are {len(features_remained)} numeric features remained.\")\n","\n","# Plot bivariate distributions \n","features_picked = features_remained[-5:]\n","df_train = X_train.loc[:, features_picked]\n","df_train['gt'] = y_train\n","fig = px.scatter_matrix(df_train, \n","                        dimensions=features_picked,\n","                        color=\"gt\", \n","                        symbol=\"gt\")\n","fig.update_traces(diagonal_visible=False)\n","fig.update_layout(height=1200, title_text=\"Bivariate Distribution of Numeric Feature Pairs (Randomly Picked)\") \n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:15:54.141607Z","iopub.status.busy":"2021-06-14T09:15:54.141164Z","iopub.status.idle":"2021-06-14T09:15:54.159996Z","shell.execute_reply":"2021-06-14T09:15:54.15918Z","shell.execute_reply.started":"2021-06-14T09:15:54.141578Z"},"trusted":true},"outputs":[],"source":["class_count = pd.DataFrame(y_train).value_counts()\n","fig = go.Figure()\n","fig.add_trace(go.Pie(\n","    labels=class_count.index,\n","    values=class_count\n","))\n","fig.update_traces(textposition='inside') \n","fig.update_layout(\n","    title=f\"Pie Chart of Groundtruths\",\n","    uniformtext_minsize=12, \n","    uniformtext_mode='hide'\n",")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:16:13.910937Z","iopub.status.busy":"2021-06-14T09:16:13.910555Z","iopub.status.idle":"2021-06-14T09:16:41.084847Z","shell.execute_reply":"2021-06-14T09:16:41.084058Z","shell.execute_reply.started":"2021-06-14T09:16:13.910902Z"},"trusted":true},"outputs":[],"source":["# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train = label_encoder.fit_transform(y_train)\n","\n","# Evaluate the model performance using KFold CV\n","kf = KFold(5, shuffle=True, random_state=42)\n","models = []   # Trained model record\n","fi = []   # Feature importance record\n","val_metrics = []   # Evaluation metrics record\n","fold = 0\n","\n","for train_idx, val_idx in kf.split(X_train):\n","    print(f\"=====Evaluation of fold{fold} starts=====\")\n","    # Prepare the training and validation sets\n","    X_train_, X_val = X_train.iloc[train_idx, :], X_train.iloc[val_idx, :]\n","    y_train_, y_val = y_train[train_idx], y_train[val_idx]\n","    \n","    # Train the classifier (rfc)\n","    rfc = RandomForestClassifier(n_estimators=500)\n","    rfc.fit(X_train_, y_train_)\n","    models.append(rfc)    # Record the trained model\n","    fi.append(rfc.feature_importances_)   # Record the feature importance\n","    \n","    # Predict and evaluate the performance\n","    y_val_pred = rfc.predict(X_val)\n","    p_r_f1_mac = list(precision_recall_fscore_support(y_val, y_val_pred, average='macro')[:3])\n","    p_r_f1_mic = list(precision_recall_fscore_support(y_val, y_val_pred, average='micro')[:3])\n","    p_r_f1_wei = list(precision_recall_fscore_support(y_val, y_val_pred, average='weighted')[:3])\n","    val_metrics.append([p_r_f1_mac, p_r_f1_mic, p_r_f1_wei])   # Concatenate the evaluation metrics and record\n","    print(f\"=====Classification Report=====\\n{classification_report(y_val, y_val_pred)}\")\n","    \n","    print(f\"=====Evaluation of fold{fold} finishes=====\\n\")\n","    fold += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:16:41.087322Z","iopub.status.busy":"2021-06-14T09:16:41.086997Z","iopub.status.idle":"2021-06-14T09:16:41.092438Z","shell.execute_reply":"2021-06-14T09:16:41.091694Z","shell.execute_reply.started":"2021-06-14T09:16:41.087293Z"},"trusted":true},"outputs":[],"source":["# Summarize the avarage performance in KFold CV\n","avg_metrics = np.mean(val_metrics, axis=0)\n","print(\"=====Average evaluatin metrics over 5 folds=====\")\n","for i, method in enumerate(['Macro', 'Micro', 'Weighted']):\n","    print(f\"=====Metrics {method}=====\")\n","    print(f\"Precision = {avg_metrics[i][0]} | Recall = {avg_metrics[i][1]} | F1-score = {avg_metrics[i][2]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:16:47.881986Z","iopub.status.busy":"2021-06-14T09:16:47.881549Z","iopub.status.idle":"2021-06-14T09:16:47.892786Z","shell.execute_reply":"2021-06-14T09:16:47.891727Z","shell.execute_reply.started":"2021-06-14T09:16:47.881958Z"},"trusted":true},"outputs":[],"source":["# Sort feature importance\n","avg_fi = np.mean(fi, axis=0)   # Calculate average feature importance over 5 folds\n","fi_dict = {}\n","for feature, feature_importance in zip(features_remained, avg_fi):\n","    fi_dict[feature] = feature_importance\n","fi_dict = dict(sorted(fi_dict.items(), key=lambda item: item[1], reverse=True))\n","\n","# Plot feature importance\n","fig = go.Figure([go.Bar(x=list(fi_dict.keys()), y=list(fi_dict.values()))])\n","fig.update_layout(title=\"Feature Importance\")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-14T09:17:01.494263Z","iopub.status.busy":"2021-06-14T09:17:01.493929Z","iopub.status.idle":"2021-06-14T09:17:02.754487Z","shell.execute_reply":"2021-06-14T09:17:02.75352Z","shell.execute_reply.started":"2021-06-14T09:17:01.494235Z"},"trusted":true},"outputs":[],"source":["# Process the data to meet the model input \n","X_test = X_test.loc[:, features_remained]\n","y_test = label_encoder.transform(y_test)\n","\n","# Do inference using trained model from each fold \n","y_test_preds = []\n","for rfc in models:\n","    y_test_pred = rfc.predict(X_test)\n","    y_test_preds.append(y_test_pred)\n","\n","# Take majority voting\n","y_test_pred_voted = np.where(\n","    np.mean(y_test_preds, axis=0) >= 0.5, \n","    1, \n","    0\n",")\n","\n","# Summarize the performance evaluated on testing set\n","print(\"=====Evaluation metrics on testing set=====\")\n","for i, method in enumerate(['Macro', 'Micro', 'Weighted']):\n","    print(f\"=====Metrics {method}=====\")\n","    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_test_pred_voted, average=method.lower())\n","    print(f\"Precision = {precision} | Recall = {recall} | F1-score = {f1_score}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
